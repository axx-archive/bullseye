{
  "project": "Bullseye",
  "branchName": "ralph/scout-tab-fixes",
  "description": "Fix Scout tab scrolling, score bars, script upload flow, metadata extraction, and reader engagement UX",
  "userStories": [
    {
      "id": "US-001",
      "title": "Fix left panel (Scout chat) scrolling",
      "description": "As a user, I want the Scout chat panel to scroll independently and auto-scroll to the latest message so I can follow the conversation.",
      "acceptanceCriteria": [
        "Left panel in scout-layout.tsx uses overflow-y-auto instead of overflow-hidden",
        "Chat messages container in scout-chat.tsx auto-scrolls to bottom when new messages arrive (useRef + scrollIntoView or scrollTop = scrollHeight)",
        "Auto-scroll only triggers if user is near the bottom (within 100px threshold) — don't interrupt if user scrolled up",
        "Right panel retains overflow-y-auto for independent user-controlled scrolling (no auto-scroll)",
        "Both panels scroll independently without affecting each other",
        "Typecheck passes",
        "Verify in browser using dev-browser skill"
      ],
      "priority": 1,
      "passes": true,
      "notes": "The left panel currently has overflow-hidden in scout-layout.tsx. The chat container in scout-chat.tsx needs a ref to track scroll position. Use useEffect watching messages length to trigger scroll. Check isNearBottom before auto-scrolling."
    },
    {
      "id": "US-002",
      "title": "Fix reader score bar visualization",
      "description": "As a user, I want to see the actual score values rendered as filled bars when reader evaluations come in.",
      "acceptanceCriteria": [
        "Debug the data flow: check if analysis_complete SSE events include scores in the payload (log the event data in event-router.ts or scout-chat.tsx)",
        "Verify readerStates in Zustand store gets populated with score objects containing numeric values for each dimension (premise, character, dialogue, structure, commerciality, overall)",
        "If the issue is the event payload: fix the reader tool (tools/readers.ts) to include scores in the analysis_complete event",
        "If the issue is the UI: fix ReaderAnalysisPanel to correctly read scores from readerStates Map entries",
        "numericToFilled() correctly converts score 0-100 to 0-10 filled bars",
        "Individual reader cards show filled colored bars for each dimension when status is 'complete'",
        "Harmonized scores section appears with golden styling and averaged bars when all 3 readers complete",
        "Recommendation badge shows correct color: recommend=green, consider=yellow, low_consider=orange, pass=red",
        "Typecheck passes",
        "Verify in browser using dev-browser skill"
      ],
      "priority": 2,
      "passes": true,
      "notes": "The ReaderAnalysisPanel code has the rendering logic for bars and harmonized scores. The issue is likely that readerStates entries don't have scores populated, or the event-router isn't mapping analysis_complete data correctly. Check the shape of data emitted by spawn_readers in tools/readers.ts vs what ReaderAnalysisPanel expects."
    },
    {
      "id": "US-003",
      "title": "Add writer field to Project model",
      "description": "As a developer, I need to store the script writer on the Project so metadata persists and can be displayed.",
      "acceptanceCriteria": [
        "Add writer String? field to Project model in prisma/schema.prisma (nullable)",
        "Run Prisma migration: npx prisma migrate dev --name add_project_writer",
        "Prisma client regenerates with writer available on Project type",
        "Typecheck passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Simple schema addition. The Project model already has genre (String) and format (ProjectFormat enum). Writer is new and nullable since existing projects won't have it."
    },
    {
      "id": "US-004",
      "title": "Auto-extract metadata from script text",
      "description": "As a user, I want Scout to automatically extract genre, format, and writer from my script so I don't have to provide that info manually.",
      "acceptanceCriteria": [
        "Create a metadata extraction step in the scout agent flow that reads the first ~5 pages (first 15000 chars) of script text",
        "Use an LLM call (via the Anthropic SDK already in the project) to extract: title, writer, genre, format from the script content",
        "LLM prompt asks for structured JSON response: { title: string, writer: string, genre: string, format: 'FEATURE' | 'TV_PILOT' | 'TV_EPISODE' | 'SHORT' }",
        "Extraction happens within the ingest_script tool or as a new step after ingest but before spawn_readers",
        "Extracted values overwrite the defaults set during pre-ingestion (genre='Drama', author='Unknown')",
        "If extraction fails or returns uncertain results, keep existing defaults gracefully (no crash)",
        "The extracted metadata is stored on the session IngestedScript object (currentScript in Zustand)",
        "Typecheck passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": "The Anthropic SDK is already imported in the project (@anthropic-ai/sdk). The extraction can use a small fast call with claude-haiku or claude-sonnet. Script text is available via currentScript.scriptText in the Zustand store or the ingest tool context. Extract from scriptText.slice(0, 15000)."
    },
    {
      "id": "US-005",
      "title": "Persist extracted metadata to Project record",
      "description": "As a developer, I need extracted metadata saved to the Project record so it's available across the app.",
      "acceptanceCriteria": [
        "After metadata extraction, update the Project record: db.project.update({ where: { id: projectId }, data: { genre, writer, format } })",
        "Only update fields that have meaningful extracted values (not 'Unknown' or 'Unclassified')",
        "If project already has a non-default genre (not 'Drama') or already has a writer set, don't overwrite (respect user-set values)",
        "The update happens in the scout API route after extraction completes (within the same request lifecycle)",
        "GET responses for projects include the writer field",
        "Typecheck passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": "The project update should guard against overwriting: if (project.genre === 'Drama' || !project.genre) update genre. if (!project.writer) update writer. The projectId is available in the scout route context."
    },
    {
      "id": "US-006",
      "title": "Display metadata pills on Home screen project cards",
      "description": "As a user, I want to see genre, format, and writer as small pills on my project cards on the Home screen.",
      "acceptanceCriteria": [
        "Home screen project cards (find the component in src/components/home/) display up to 3 metadata pills in a flex-wrap row",
        "Genre pill: shows extracted genre string (e.g., 'Action/Thriller', 'Drama') — skip if null or 'Unclassified'",
        "Format pill: shows human-readable label ('Feature', 'TV Pilot', 'Short', 'TV Episode', 'Limited Series', 'Documentary') — not the raw enum value",
        "Writer pill: shows author name — skip if null or 'Unknown'",
        "Pill styling: text-xs bg-muted/50 text-muted-foreground rounded-full px-2 py-0.5",
        "Pills wrap to second line if needed (container uses flex-wrap gap-1)",
        "Typecheck passes",
        "Verify in browser using dev-browser skill"
      ],
      "priority": 6,
      "passes": false,
      "notes": "Find the project card component in src/components/home/. The Project data should already be fetched with the writer field after US-003 migration. Map ProjectFormat enum to display labels: FEATURE→'Feature', TV_PILOT→'TV Pilot', etc."
    },
    {
      "id": "US-007",
      "title": "Script upload immediately engages Scout and readers",
      "description": "As a user, I want the center upload prompt to hand off my script to Scout and immediately start reader analysis without extra steps.",
      "acceptanceCriteria": [
        "When user uploads via center EmptyState prompt, script is sent to Scout with message 'Analyze this script' (existing pendingScoutAttachment flow)",
        "Scout immediately ingests (extracts metadata) and proceeds to spawn_readers without asking any questions",
        "The right panel switches from idle to analysis mode showing reader progress cards",
        "Upload flow works identically whether triggered from center prompt or chat attachment button",
        "No intermediate questions from Scout about genre/format/writer (those are auto-extracted)",
        "Typecheck passes",
        "Verify in browser using dev-browser skill"
      ],
      "priority": 7,
      "passes": false,
      "notes": "The existing pendingScoutAttachment auto-send effect in scout-chat.tsx already sends 'Analyze this script'. The key change is ensuring Scout's system prompt doesn't ask for clarification — it just proceeds. This depends on US-009 (prompt update)."
    },
    {
      "id": "US-008",
      "title": "Scout gives process heads-up before engaging readers",
      "description": "As a user, I want Scout to briefly explain what's about to happen before engaging the readers so I understand the process.",
      "acceptanceCriteria": [
        "After ingesting a script, before calling spawn_readers, Scout sends an orientation message to the user",
        "Message content: 'I'm sending your script to three readers — Maya Chen (The Optimist), Colton Rivers (The Skeptic), and Devon Park (The Craftsman). They'll each provide independent evaluations across premise, character, dialogue, structure, and commerciality. Once all three finish, I'll harmonize their scores into a unified coverage report. You can follow their progress in the panel on the right.'",
        "This orientation only happens on the FIRST analysis in a session (not on re-analysis or subsequent scripts in same session)",
        "The message appears as a regular Scout chat message in the left panel (not a toast or system message)",
        "Add this behavior to the SCOUT_AGENT_SYSTEM_PROMPT as a required step between ingest and spawn_readers",
        "Typecheck passes"
      ],
      "priority": 8,
      "passes": false,
      "notes": "Add instruction to the system prompt after the ingest step: 'Before spawning readers for the FIRST script in a session, send a brief orientation message explaining the process.' The agent will naturally emit this as a text_delta event which renders in the chat."
    },
    {
      "id": "US-009",
      "title": "Remove metadata questions from Scout system prompt",
      "description": "As a developer, I need to update the Scout agent system prompt to stop asking users for genre/format/writer since it's now auto-extracted.",
      "acceptanceCriteria": [
        "In src/lib/agent-sdk/prompts.ts, update SCOUT_AGENT_SYSTEM_PROMPT step 1 (Acknowledge & Clarify)",
        "Remove: 'Ask about genre, format, and any specific concerns'",
        "Replace with: 'Extract metadata (genre, format, writer) automatically from the script text. Do not ask the user for this information.'",
        "Keep an optional note: 'If the user volunteers specific concerns or focus areas in their message, note them for the readers.'",
        "Add instruction: 'If user provides genre/format/writer explicitly in their message, use that instead of extracting.'",
        "Scout no longer asks clarifying questions about the script before proceeding — just extracts and goes",
        "Typecheck passes"
      ],
      "priority": 9,
      "passes": false,
      "notes": "The system prompt is in src/lib/agent-sdk/prompts.ts. The 'Acknowledge & Clarify' step is around lines 68-73. Update it to reflect the new auto-extraction flow. This is the foundational change that makes US-007 and US-008 work correctly."
    }
  ]
}
